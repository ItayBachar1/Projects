{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Project \"Meditest×´</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to COVID-19 there is a high demand for identifying at-risk population to provide necessary aid. For this purpose, \"Meditest\" company recruited two teams to build classifiers for at-risk population. Each of these teams suggeted a classifier that was trained on data gathered from thousands of people including medical information such as pre-existing condition, blood pressure and pulse. For each given person, the classifier predicts whether he belongs to in-risk population or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the classifiers and choose the better one, \"Meditest\" company assembled real classification data on a group of 40 people in which it is known if they belong to at-risk population or not. This group of people was not included in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real data is presented below:<br>0 - Does not belong to at-risk population<br>1 - Belongs to at-risk population "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=100) # for printing each array in a single line\n",
    "\n",
    "# The real_data Numpy array contains 40 items representing the real data gathered by \"Meditest\".\n",
    "# Each item in the Numpy array represents the true and reliable classification of a person. \n",
    "# 0 - does not belong to at risk population, 1 - belongs to at risk population.\n",
    "# For example, the person in index 0 is not at risk, while the last one (index 39) is at risk\n",
    "\n",
    "real_data    = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The company's management team asks your help in choosing the most suitable classifier among the following suggested classifiers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each item in each of the following Numpy arrays represents the predicted classification of a person. \n",
    "\n",
    "classifier_1 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1])\n",
    "classifier_2 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the classifiers will you recommend - classifier_1 or classifier_2? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< Write your answer here - no need for code, but you can use code if it helps in choosing a classifier >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each item in each of the following Numpy arrays represents the predicted classification of a person. \n",
    "\n",
    "classifier_3 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
    "classifier_4 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the classifiers will you recommend - classifier_3 or classifier_4? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< Write your answer here - no need for code, but you can use code if it helps in choosing a classifier >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggest a numeric measure to estimate how good a classifier is. Higher number indicates a better classifier. Describe the measure in words, how would you calculate it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< Write your answer here >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement your suggested measure. The measure gets two Numpy arrays as input; The first represents the real data, and the second represents the classifier's estimation. The measure should return a score (number) to indicate how good the classifier is. A higher score indicates a better classifier.\n",
    "\n",
    "You can use the attached example of a measure you already fimiliar with - the accuracy score. It just calculates the proportion of the correct estimations of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: write your code in the provided code cells and **do not** change the signature of the method. That is, do not change the names of the methods (e.g., calculate_measure) or the input parameters (real_data, classifier_results). Delete the 'pass' keyword and fill your code instead.\n",
    "\n",
    "**Notice**: There is more than one possible solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier measurement example - accuracy\n",
    "def calculate_accuracy(real_data, classifier_results):\n",
    "    correct = 0\n",
    "    for person_index in range(len(real_data)):\n",
    "        if real_data[person_index] == classifier_results[person_index]:\n",
    "            correct += 1\n",
    "    \n",
    "    success_rate = correct / len(real_data)\n",
    "    return success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_measure(real_data, classifier_results):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your measure on the classifiers provided earlier. Does your measure score supports your choices in task 1a and task 1b?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "print(calculate_measure(real_data, classifier_1))\n",
    "print(calculate_measure(real_data, classifier_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please submit your notebook in the following link: <a href=\"http://3.128.181.72\">Invention activities submission framework</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
